{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Storing Processed Data into Pickle and npy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     building_id  meter            timestamp  meter_reading\n",
      "103          105      0  2016-01-01 00:00:00        23.3036\n",
      "104          106      0  2016-01-01 00:00:00         0.3746\n",
      "105          106      3  2016-01-01 00:00:00         0.0000\n",
      "106          107      0  2016-01-01 00:00:00       175.1840\n",
      "107          108      0  2016-01-01 00:00:00        91.2653\n",
      "   site_id  building_id primary_use  square_feet  year_built  floor_count\n",
      "0        0            0   Education         7432      2008.0          NaN\n",
      "1        0            1   Education         2720      2004.0          NaN\n",
      "2        0            2   Education         5376      1991.0          NaN\n",
      "3        0            3   Education        23685      2002.0          NaN\n",
      "4        0            4   Education       116607      1975.0          NaN\n",
      "   site_id            timestamp  air_temperature  cloud_coverage  \\\n",
      "0        0  2016-01-01 00:00:00             25.0             6.0   \n",
      "1        0  2016-01-01 01:00:00             24.4             NaN   \n",
      "2        0  2016-01-01 02:00:00             22.8             2.0   \n",
      "3        0  2016-01-01 03:00:00             21.1             2.0   \n",
      "4        0  2016-01-01 04:00:00             20.0             2.0   \n",
      "\n",
      "   dew_temperature  precip_depth_1_hr  sea_level_pressure  wind_direction  \\\n",
      "0             20.0                NaN              1019.7             0.0   \n",
      "1             21.1               -1.0              1020.2            70.0   \n",
      "2             21.1                0.0              1020.2             0.0   \n",
      "3             20.6                0.0              1020.1             0.0   \n",
      "4             20.0               -1.0              1020.0           250.0   \n",
      "\n",
      "   wind_speed  \n",
      "0         0.0  \n",
      "1         1.5  \n",
      "2         0.0  \n",
      "3         0.0  \n",
      "4         2.6  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import gc\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "# Constants for data paths\n",
    "DATA_PATH = \"dataset/\"\n",
    "TRAIN_FILE = 'train.csv'\n",
    "BUILDING_METADATA_FILE = 'building_metadata.csv'\n",
    "WEATHER_TRAIN_FILE = 'weather_train.csv'\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(DATA_PATH + TRAIN_FILE)\n",
    "building_df = pd.read_csv(DATA_PATH + BUILDING_METADATA_FILE)\n",
    "weather_df = pd.read_csv(DATA_PATH + WEATHER_TRAIN_FILE)\n",
    "\n",
    "# Remove specific outliers\n",
    "train_df = train_df[train_df['building_id'] != 1099]\n",
    "train_df = train_df.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')\n",
    "\n",
    "print(train_df.head())\n",
    "print(building_df.head())\n",
    "print(weather_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_weather_dataset(weather_df):\n",
    "    \n",
    "    # Find Missing Dates\n",
    "    time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    start_date = datetime.datetime.strptime(weather_df['timestamp'].min(),time_format)\n",
    "    end_date = datetime.datetime.strptime(weather_df['timestamp'].max(),time_format)\n",
    "    total_hours = int(((end_date - start_date).total_seconds() + 3600) / 3600)\n",
    "    hours_list = [(end_date - datetime.timedelta(hours=x)).strftime(time_format) for x in range(total_hours)]\n",
    "\n",
    "    missing_hours = []\n",
    "    for site_id in range(16):\n",
    "        site_hours = np.array(weather_df[weather_df['site_id'] == site_id]['timestamp'])\n",
    "        new_rows = pd.DataFrame(np.setdiff1d(hours_list,site_hours),columns=['timestamp'])\n",
    "        new_rows['site_id'] = site_id\n",
    "        weather_df = pd.concat([weather_df,new_rows])\n",
    "\n",
    "        weather_df = weather_df.reset_index(drop=True)           \n",
    "\n",
    "    # Add new Features\n",
    "    weather_df[\"datetime\"] = pd.to_datetime(weather_df[\"timestamp\"])\n",
    "    weather_df[\"day\"] = weather_df[\"datetime\"].dt.day\n",
    "    weather_df[\"week\"] = weather_df[\"datetime\"].dt.weekday\n",
    "    weather_df[\"month\"] = weather_df[\"datetime\"].dt.month\n",
    "    \n",
    "    # Reset Index for Fast Update\n",
    "    weather_df = weather_df.set_index(['site_id','day','month'])\n",
    "\n",
    "    air_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['air_temperature'].mean(),columns=[\"air_temperature\"])\n",
    "    weather_df.update(air_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    cloud_coverage_filler = weather_df.groupby(['site_id','day','month'])['cloud_coverage'].mean()\n",
    "    # Step 2\n",
    "    cloud_coverage_filler = pd.DataFrame(cloud_coverage_filler.fillna(method='ffill'),columns=[\"cloud_coverage\"])\n",
    "\n",
    "    weather_df.update(cloud_coverage_filler,overwrite=False)\n",
    "\n",
    "    due_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['dew_temperature'].mean(),columns=[\"dew_temperature\"])\n",
    "    weather_df.update(due_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    sea_level_filler = weather_df.groupby(['site_id','day','month'])['sea_level_pressure'].mean()\n",
    "    # Step 2\n",
    "    sea_level_filler = pd.DataFrame(sea_level_filler.fillna(method='ffill'),columns=['sea_level_pressure'])\n",
    "\n",
    "    weather_df.update(sea_level_filler,overwrite=False)\n",
    "\n",
    "    wind_direction_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_direction'].mean(),columns=['wind_direction'])\n",
    "    weather_df.update(wind_direction_filler,overwrite=False)\n",
    "\n",
    "    wind_speed_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_speed'].mean(),columns=['wind_speed'])\n",
    "    weather_df.update(wind_speed_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    precip_depth_filler = weather_df.groupby(['site_id','day','month'])['precip_depth_1_hr'].mean()\n",
    "    # Step 2\n",
    "    precip_depth_filler = pd.DataFrame(precip_depth_filler.fillna(method='ffill'),columns=['precip_depth_1_hr'])\n",
    "\n",
    "    weather_df.update(precip_depth_filler,overwrite=False)\n",
    "\n",
    "    weather_df = weather_df.reset_index()\n",
    "    weather_df = weather_df.drop(['datetime','day','week','month'],axis=1)\n",
    "        \n",
    "    return weather_df\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\"\n",
    "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def features_engineering(df):\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    df.sort_values(\"timestamp\")\n",
    "    df.reset_index(drop=True)\n",
    "    \n",
    "    # Add more features\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"],format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "    df[\"weekend\"] = df[\"timestamp\"].dt.weekday\n",
    "    holidays = [\"2016-01-01\", \"2016-01-18\", \"2016-02-15\", \"2016-05-30\", \"2016-07-04\",\n",
    "                    \"2016-09-05\", \"2016-10-10\", \"2016-11-11\", \"2016-11-24\", \"2016-12-26\",\n",
    "                    \"2017-01-02\", \"2017-01-16\", \"2017-02-20\", \"2017-05-29\", \"2017-07-04\",\n",
    "                    \"2017-09-04\", \"2017-10-09\", \"2017-11-10\", \"2017-11-23\", \"2017-12-25\",\n",
    "                    \"2018-01-01\", \"2018-01-15\", \"2018-02-19\", \"2018-05-28\", \"2018-07-04\",\n",
    "                    \"2018-09-03\", \"2018-10-08\", \"2018-11-12\", \"2018-11-22\", \"2018-12-25\",\n",
    "                    \"2019-01-01\"]\n",
    "    df[\"is_holiday\"] = (df.timestamp.isin(holidays)).astype(int)\n",
    "    df['square_feet'] =  np.log1p(df['square_feet']**0.5)\n",
    "    \n",
    "    # Remove Unused Columns\n",
    "    drop = [\"timestamp\",\"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"year_built\",\"floor_count\"]\n",
    "    df = df.drop(drop, axis=1)\n",
    "    gc.collect()\n",
    "    \n",
    "    # Encode Categorical Data\n",
    "    le = LabelEncoder()\n",
    "    df[\"primary_use\"] = le.fit_transform(df[\"primary_use\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:34: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  cloud_coverage_filler = pd.DataFrame(cloud_coverage_filler.fillna(method='ffill'),columns=[\"cloud_coverage\"])\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:44: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sea_level_filler = pd.DataFrame(sea_level_filler.fillna(method='ffill'),columns=['sea_level_pressure'])\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:57: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  precip_depth_filler = pd.DataFrame(precip_depth_filler.fillna(method='ffill'),columns=['precip_depth_1_hr'])\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 757.31 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_22476\\3594232981.py:75: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 322.18 MB\n",
      "Decreased by 57.5%\n",
      "Memory usage of dataframe is 0.07 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by 73.9%\n",
      "Memory usage of dataframe is 9.65 MB\n",
      "Memory usage after optimization is: 2.60 MB\n",
      "Decreased by 73.1%\n",
      "   building_id     meter   site_id  primary_use  square_feet  air_temperature  \\\n",
      "0     0.000442  0.589652  0.027874     0.405518     5.420515         3.800781   \n",
      "1     0.000885  0.589652  0.027874     0.405518     4.308213         3.800781   \n",
      "2     0.000885  0.063672  0.027874     0.405518     4.308213         3.800781   \n",
      "3     0.000442  0.589652  0.027874     0.405518     5.747165         3.800781   \n",
      "4     0.000442  0.589652  0.027874     0.405518     5.658165         3.800781   \n",
      "\n",
      "   cloud_coverage  dew_temperature  precip_depth_1_hr  \n",
      "0             0.0         2.400391                0.0  \n",
      "1             0.0         2.400391                0.0  \n",
      "2             0.0         2.400391                0.0  \n",
      "3             0.0         2.400391                0.0  \n",
      "4             0.0         2.400391                0.0  \n",
      "   building_id     meter   site_id  primary_use  square_feet  air_temperature  \\\n",
      "0     0.000442  0.589652  0.027874     0.405518     5.420515         3.800781   \n",
      "1     0.000885  0.589652  0.027874     0.405518     4.308213         3.800781   \n",
      "2     0.000885  0.063672  0.027874     0.405518     4.308213         3.800781   \n",
      "3     0.000442  0.589652  0.027874     0.405518     5.747165         3.800781   \n",
      "4     0.000442  0.589652  0.027874     0.405518     5.658165         3.800781   \n",
      "\n",
      "   cloud_coverage  dew_temperature  precip_depth_1_hr  \n",
      "0             0.0         2.400391                0.0  \n",
      "1             0.0         2.400391                0.0  \n",
      "2             0.0         2.400391                0.0  \n",
      "3             0.0         2.400391                0.0  \n",
      "4             0.0         2.400391                0.0  \n"
     ]
    }
   ],
   "source": [
    "weather_df = fill_weather_dataset(weather_df)\n",
    "train_df = reduce_mem_usage(train_df,use_float16=True)\n",
    "building_df = reduce_mem_usage(building_df,use_float16=True)\n",
    "weather_df = reduce_mem_usage(weather_df,use_float16=True)\n",
    "train_df = train_df.merge(building_df, left_on='building_id',right_on='building_id',how='left')\n",
    "train_df = train_df.merge(weather_df,how='left',left_on=['site_id','timestamp'],right_on=['site_id','timestamp'])\n",
    "del weather_df\n",
    "gc.collect()\n",
    "train_df = features_engineering(train_df)\n",
    "target = np.log1p(train_df[\"meter_reading\"])\n",
    "train = train_df.drop(['meter_reading', 'is_holiday', 'hour', 'weekend'], axis = 1)\n",
    "del train_df\n",
    "gc.collect()\n",
    "categorical_features = [\"building_id\", \"site_id\", \"meter\", \"primary_use\"]\n",
    "import category_encoders\n",
    "ce = category_encoders.CountEncoder(cols=categorical_features)\n",
    "ce.fit(train)\n",
    "train = ce.transform(train)\n",
    "train.head()\n",
    "N_train = train.shape[0]\n",
    "for feature in categorical_features:\n",
    "    train[feature] = train[feature]/N_train\n",
    "print(train.head())\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(train)\n",
    "train_imputed = imp.transform(train)\n",
    "train_imputed_df = pd.DataFrame(train_imputed, columns=train.columns)\n",
    "train = train_imputed_df\n",
    "print(train.head())\n",
    "# store train data and target for easier use using pickle\n",
    "import pickle\n",
    "with open('dataset/train.pkl', 'wb') as f:\n",
    "    pickle.dump(train, f)\n",
    "with open('dataset/target.pkl', 'wb') as f:\n",
    "    pickle.dump(target, f)\n",
    "\n",
    "\n",
    "# save as npy array\n",
    "np.save('dataset/train.npy', train)\n",
    "np.save('dataset/target.npy', target)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.589652</td>\n",
       "      <td>0.027874</td>\n",
       "      <td>0.405518</td>\n",
       "      <td>5.420515</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.589652</td>\n",
       "      <td>0.027874</td>\n",
       "      <td>0.405518</td>\n",
       "      <td>4.308213</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.063672</td>\n",
       "      <td>0.027874</td>\n",
       "      <td>0.405518</td>\n",
       "      <td>4.308213</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.589652</td>\n",
       "      <td>0.027874</td>\n",
       "      <td>0.405518</td>\n",
       "      <td>5.747165</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.589652</td>\n",
       "      <td>0.027874</td>\n",
       "      <td>0.405518</td>\n",
       "      <td>5.658165</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id     meter   site_id  primary_use  square_feet  air_temperature  \\\n",
       "0     0.000442  0.589652  0.027874     0.405518     5.420515         3.800781   \n",
       "1     0.000885  0.589652  0.027874     0.405518     4.308213         3.800781   \n",
       "2     0.000885  0.063672  0.027874     0.405518     4.308213         3.800781   \n",
       "3     0.000442  0.589652  0.027874     0.405518     5.747165         3.800781   \n",
       "4     0.000442  0.589652  0.027874     0.405518     5.658165         3.800781   \n",
       "\n",
       "   cloud_coverage  dew_temperature  precip_depth_1_hr  \n",
       "0             0.0         2.400391                0.0  \n",
       "1             0.0         2.400391                0.0  \n",
       "2             0.0         2.400391                0.0  \n",
       "3             0.0         2.400391                0.0  \n",
       "4             0.0         2.400391                0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
