{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Tuned Models Results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickle file train from dataset/train.pkl and target from dataset/target.pkl\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('dataset/train.pkl', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open('dataset/target.pkl', 'rb') as f:\n",
    "    target = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1915660940222301\n",
      "RMSE: 1.1647653628494292\n",
      "RMSE: 1.208591522100199\n",
      "RMSE: 1.2674121916968033\n",
      "RMSE: 1.1500745311872123\n",
      "Average RMSE: 1.1964819403711748\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Create an instance of KFold with the specified number of folds\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "rmse_scores_lightgbm = []\n",
    "\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Create an instance of lgb.Dataset for the training and testing sets\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_test = lgb.Dataset(X_test, y_test)\n",
    "\n",
    "    # Define the parameters for the LightGBM model\n",
    "    params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 100,\n",
    "    'learning_rate': 0.09841079471843048,\n",
    "    'feature_fraction': 0.6146295376710438,\n",
    "    'bagging_fraction': 0.6360723189013848,\n",
    "    'bagging_freq': 7,\n",
    "    'verbose': 0\n",
    "    }\n",
    "\n",
    "    # Train the LightGBM model\n",
    "    model = lgb.train(params, lgb_train, num_boost_round=100)\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate the RMSE for the current fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    # Print the RMSE for the current fold\n",
    "    print(\"RMSE:\", rmse)\n",
    "\n",
    "    # Append the RMSE to the list of scores\n",
    "    rmse_scores_lightgbm.append(rmse)\n",
    "\n",
    "\n",
    "# Calculate the average RMSE across all folds\n",
    "average_rmse = np.mean(rmse_scores_lightgbm)\n",
    "\n",
    "# Print the average RMSE\n",
    "print(\"Average RMSE:\", average_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.9641591\ttest: 2.0062060\tbest: 2.0062060 (0)\ttotal: 1.7s\tremaining: 2m 48s\n",
      "99:\tlearn: 1.2034665\ttest: 1.2582424\tbest: 1.2582424 (99)\ttotal: 2m 29s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.258242419\n",
      "bestIteration = 99\n",
      "\n",
      "CatBoost RMSE: 1.2582424187423533\n",
      "0:\tlearn: 1.9768329\ttest: 1.9365990\tbest: 1.9365990 (0)\ttotal: 1.59s\tremaining: 2m 37s\n",
      "99:\tlearn: 1.2050881\ttest: 1.2337259\tbest: 1.2337259 (99)\ttotal: 2m 29s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.233725865\n",
      "bestIteration = 99\n",
      "\n",
      "CatBoost RMSE: 1.233725864789475\n",
      "0:\tlearn: 1.9671160\ttest: 1.9887284\tbest: 1.9887284 (0)\ttotal: 1.47s\tremaining: 2m 25s\n",
      "99:\tlearn: 1.1998497\ttest: 1.2782789\tbest: 1.2782789 (99)\ttotal: 2m 26s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.278278939\n",
      "bestIteration = 99\n",
      "\n",
      "CatBoost RMSE: 1.2782789393517557\n",
      "0:\tlearn: 1.9646954\ttest: 1.9952645\tbest: 1.9952645 (0)\ttotal: 1.53s\tremaining: 2m 31s\n",
      "99:\tlearn: 1.1782875\ttest: 1.3373470\tbest: 1.3373470 (99)\ttotal: 2m 31s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.337346967\n",
      "bestIteration = 99\n",
      "\n",
      "CatBoost RMSE: 1.3373469672035596\n",
      "0:\tlearn: 1.9761808\ttest: 1.9485847\tbest: 1.9485847 (0)\ttotal: 1.73s\tremaining: 2m 51s\n",
      "99:\tlearn: 1.2125419\ttest: 1.2120437\tbest: 1.2120437 (99)\ttotal: 2m 35s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.212043683\n",
      "bestIteration = 99\n",
      "\n",
      "CatBoost RMSE: 1.2120436829539742\n",
      "Average CatBoost RMSE: 1.2639275746082235\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Create an instance of KFold with the specified number of folds\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Initialize an empty list to store the RMSE for each fold\n",
    "catboost_rmse_scores = []\n",
    "\n",
    "# Specify the parameters for the CatBoost model\n",
    "params = {\n",
    "    'iterations': 100,\n",
    "    'learning_rate': 0.15,\n",
    "    'depth': 10,\n",
    "    'loss_function': 'RMSE'\n",
    "}\n",
    "\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Split the data\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    # Create an instance of CatBoostRegressor\n",
    "    model = CatBoostRegressor(**params)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=100)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE and append to the list\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"CatBoost RMSE:\", rmse)\n",
    "    catboost_rmse_scores.append(rmse)\n",
    "\n",
    "# Calculate the average RMSE\n",
    "average_catboost_rmse = np.mean(catboost_rmse_scores)\n",
    "print(\"Average CatBoost RMSE:\", average_catboost_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dublu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m7755/7755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 6ms/step - loss: 1.8226 - val_loss: 1.5620\n",
      "Epoch 2/15\n",
      "\u001b[1m7755/7755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - loss: 1.5756 - val_loss: 1.4997\n",
      "Epoch 3/15\n",
      "\u001b[1m7755/7755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - loss: 1.5227 - val_loss: 1.4749\n",
      "Epoch 4/15\n",
      "\u001b[1m7755/7755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - loss: 1.4958 - val_loss: 1.4590\n",
      "Epoch 5/15\n",
      "\u001b[1m7755/7755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 6ms/step - loss: 1.4801 - val_loss: 1.4383\n",
      "Epoch 6/15\n",
      "\u001b[1m7755/7755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 6ms/step - loss: 1.4667 - val_loss: 1.4383\n",
      "Epoch 7/15\n",
      "\u001b[1m7755/7755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 6ms/step - loss: 1.4582 - val_loss: 1.4182\n",
      "Epoch 8/15\n",
      "\u001b[1m7755/7755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - loss: 1.4499 - val_loss: 1.4148\n",
      "Epoch 9/15\n",
      "\u001b[1m7755/7755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - loss: 1.4429 - val_loss: 1.4075\n",
      "Epoch 10/15\n",
      "\u001b[1m7755/7755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 6ms/step - loss: 1.4374 - val_loss: 1.3986\n",
      "Epoch 11/15\n",
      "\u001b[1m7755/7755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - loss: 1.4315 - val_loss: 1.3864\n",
      "Epoch 12/15\n",
      "\u001b[1m7755/7755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 6ms/step - loss: 1.4263 - val_loss: 1.3689\n",
      "Epoch 13/15\n",
      "\u001b[1m7755/7755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 6ms/step - loss: 1.4228 - val_loss: 1.3761\n",
      "Epoch 14/15\n",
      "\u001b[1m7755/7755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 6ms/step - loss: 1.4188 - val_loss: 1.3727\n",
      "Epoch 15/15\n",
      "\u001b[1m7755/7755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 6ms/step - loss: 1.4165 - val_loss: 1.3701\n",
      "Neural Network Training RMSLE =  1.2749000787734985\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,880</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">64,736</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)            │         \u001b[38;5;34m2,880\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │        \u001b[38;5;34m64,736\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │        \u001b[38;5;34m21,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m97\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">267,941</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m267,941\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,313</span> (348.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,313\u001b[0m (348.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">178,628</span> (697.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m178,628\u001b[0m (697.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "from graphviz import Digraph\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def NN_RMSLE(y_actual, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_actual))) \n",
    "\n",
    "train_xx, val_xx, train_yy, val_yy = train_test_split(train, target, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "earlyStop= EarlyStopping(monitor='val_loss', mode='min', patience=3)\n",
    "\n",
    "model.add(layers.Dense(288, activation='relu',input_shape=(train_xx.shape[1],)))\n",
    "model.add(Dropout(0))\n",
    "model.add(layers.Dense(224, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(96, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1  ,activation='linear'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss = NN_RMSLE)\n",
    "\n",
    "model.fit(train_xx, train_yy, epochs = 15, batch_size = 2048, validation_data=(val_xx,val_yy),callbacks = earlyStop)\n",
    "print('Neural Network Training RMSLE = ', model.evaluate(train, target, verbose=0))\n",
    "model.save('tuned_3layer.keras')\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
